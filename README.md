# LSTM Text Prediction App ğŸš€

A modern, real-time text prediction application powered by LSTM neural networks. Features a sleek UI with instant word suggestions as you type, similar to modern text editors and IDEs.

![Demo](https://img.shields.io/badge/Status-Active-brightgreen) ![Python](https://img.shields.io/badge/Python-3.9+-blue) ![TensorFlow](https://img.shields.io/badge/TensorFlow-2.19.0-orange) ![JavaScript](https://img.shields.io/badge/JavaScript-ES6+-yellow)

## âœ¨ Features

- **Real-time Predictions**: LSTM-powered word predictions as you type
- **Modern UI**: Glassmorphic design with smooth animations
- **Instant Suggestions**: Tab to accept, Esc to dismiss
- **Live Statistics**: Real-time word and character counts
- **Smart Cursor**: Maintains cursor position after predictions
- **Server Status**: Visual connection indicator
- **Copy to Clipboard**: One-click text copying
- **Responsive Design**: Works on desktop and mobile

## ğŸ› ï¸ Tech Stack

### Backend
- **Python 3.9+**
- **Flask** - Web framework
- **TensorFlow 2.19.0** - LSTM model
- **Flask-CORS** - Cross-origin requests

### Frontend
- **HTML5** - Semantic markup
- **CSS3** - Modern styling with glassmorphism
- **Vanilla JavaScript** - Real-time interactions
- **REST API** - Backend communication

## ğŸš€ Quick Start

### Prerequisites

- Python 3.9 or higher
- Node.js (for development server, optional)
- Modern web browser

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/lstm-text-predictor.git
   cd lstm-text-predictor
   ```

2. **Set up the backend**
   ```bash
   cd backend
   pip install -r requirements.txt
   ```

3. **Start the Flask server**
   ```bash
   python app.py
   ```
   Server will run on `http://localhost:5000`

4. **Launch the frontend**
   ```bash
   cd ../frontend
   # Open index.html in your browser or use a local server
   python -m http.server 8080
   ```
   Frontend available at `http://localhost:8080`

## ğŸ“ Project Structure

```
lstm-text-predictor/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py              # Flask API server
â”‚   â”œâ”€â”€ model.py            # LSTM model definition
â”‚   â”œâ”€â”€ train.py            # Model training script
â”‚   â”œâ”€â”€ requirements.txt    # Python dependencies
â”‚   â””â”€â”€ models/             # Saved model files
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html          # Main HTML file
â”‚   â”œâ”€â”€ style.css           # Styling and animations
â”‚   â”œâ”€â”€ script.js           # JavaScript functionality
â”‚   â””â”€â”€ assets/             # Static assets
â”œâ”€â”€ data/
â”‚   â””â”€â”€ training_data.txt   # Text corpus for training
â””â”€â”€ README.md
```

## ğŸ¯ Usage

1. **Start typing** in the text editor
2. **View predictions** in the suggestions panel
3. **Press Tab** to accept the first suggestion
4. **Press Esc** to clear suggestions
5. **Click suggestions** to insert them directly
6. **Use keyboard shortcuts** for efficient editing

### Keyboard Shortcuts

| Shortcut | Action |
|----------|---------|
| `Tab` | Accept first prediction |
| `Esc` | Clear predictions |
| `Ctrl + Enter` | New line |
| `Arrow Keys` | Navigate suggestions |

## ğŸ¤– Model Training

To train your own LSTM model:

1. **Prepare your dataset**
   ```python
   # Place your text data in data/training_data.txt
   ```

2. **Run training script**
   ```bash
   cd backend
   python train.py
   ```

3. **Model parameters**
   - Sequence length: 40 characters
   - LSTM units: 256
   - Dropout: 0.3
   - Epochs: 50

## ğŸ”§ API Endpoints

### `GET /health`
Check server status
```json
{
  "status": "healthy",
  "model_loaded": true
}
```

### `POST /predict`
Get word predictions
```json
// Request
{
  "text": "The quick brown",
  "max_predictions": 5
}

// Response
{
  "predictions": ["fox", "dog", "cat", "bird", "rabbit"]
}
```

## ğŸ¨ Customization

### Styling
- Modify `frontend/style.css` for visual changes
- Glassmorphic design with CSS backdrop-filter
- Responsive grid layout

### Model Parameters
- Adjust LSTM layers in `backend/model.py`
- Modify sequence length for different contexts
- Change vocabulary size for domain-specific text

### Prediction Logic
- Edit `backend/app.py` for custom prediction algorithms
- Implement confidence scoring
- Add text preprocessing steps

## ğŸ› Troubleshooting

### Common Issues

**Server Connection Failed**
```bash
# Check if Flask server is running
curl http://localhost:5000/health
```

**Model Loading Error**
```bash
# Verify TensorFlow installation
python -c "import tensorflow as tf; print(tf.__version__)"
```

**CORS Issues**
```bash
# Ensure flask-cors is installed
pip install flask-cors
```

## ğŸš§ Development

### Running in Development Mode

```bash
# Backend with auto-reload
export FLASK_ENV=development
python app.py

# Frontend with live reload (optional)
npm install -g live-server
live-server frontend/
```

### Testing

```bash
# Test API endpoints
python -m pytest tests/

# Frontend testing in browser console
window.textPredictor.checkServerStatus()
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Development Guidelines

- Follow PEP 8 for Python code
- Use ES6+ JavaScript features
- Add comments for complex logic
- Test on multiple browsers
- Ensure responsive design

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- TensorFlow team for the amazing ML framework
- Flask community for the lightweight web framework
- Open source datasets for training data
- Modern web standards for glassmorphic design inspiration

## ğŸ“Š Performance

- **Prediction Speed**: < 100ms average response time
- **Model Size**: ~50MB (optimized for web deployment)
- **Memory Usage**: ~200MB during inference
- **Browser Support**: Chrome 90+, Firefox 88+, Safari 14+

## ğŸ”® Future Enhancements

- [ ] Multi-language support
- [ ] Context-aware predictions
- [ ] User personalization
- [ ] Voice input integration
- [ ] Mobile app version
- [ ] Cloud deployment ready
- [ ] Real-time collaboration

---

â­ **Star this repo** if you find it helpful!
